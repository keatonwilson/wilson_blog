---
title: Bean Market Predictions using Machine Learning Algorithms
author: ''
date: '2018-04-21'
slug: bean-market-predictions-using-machine-learning-algorithms
categories:
  - bean project
  - data science
  - machine learning
tags:
  - beans  
summary: >
  Finally, we get to some machine learning models. I go over using the functions in the caret package to build, test and tune a variety of models, and end up with a nice Random Forest model that does a very solid job predicting bean market prices 6 months in the future. We finish up with a little bit of data viz to assess our prediction power. 
---

### Goals

As I've discussed in earlier posts, the basic premise of this project was to use a nice (but messy) dataset from the USDA on domestic bean markets to explore a variety of different avenues of analysis, visualization and data exploration. One of the main goals of this project was to see if I could build some machine learning models that do a good job of predicting future prices of different classes of beans. 

In past posts we've worked to [import messy data from Excel files](keatonwilson.github.io/2018/03/bean-munging-and-excel-wrangling/), and [preprocessing data using the caret package](keatonwilson.github.io/2018/04/preprocessing-bean-data-on-the-road-to-machine-learning/) to make sure it's ready for running some building, testing and tuning some machine learning algorithms.

We're going to start with the preprocessed data set outlined in my last post. Let's give it a lookover to remind ourselves what's in it (and load up our packages)

``` {r, echo = FALSE, message = FALSE, results = "hide", warning = FALSE}
#Loading in everything that we need to get to the preprocessing
#reading in the bean_master file

library(tidyverse)
library(caret)
library(lubridate)
bean_master_import = read_csv(file = "https://raw.githubusercontent.com/keatonwilson/beans/master/data/bean_master_joined.csv")
#Adding future month and year
bean_master_import = bean_master_import %>%
  mutate(future_month = month(future_date, label = TRUE, abbr = FALSE),
         future_year = year(future_date)) 

#Making the dataframe we're going to join
bean_master_future_to_join = bean_master_import %>%
  group_by(class, year, month) %>%
  summarize(monthly_average_price = mean(price))

#joining it back on, but with the key column set to future date instead of date
bean_master_import = bean_master_import %>%
  inner_join(bean_master_future_to_join, by = c("future_year" = "year", "future_month" = "month", "class" = "class")) %>%
  rename(future_monthly_average_price = monthly_average_price) 

#Looks reasonable
head(bean_master_import$future_monthly_average_price, n = 20)

#This looks reasonable too
select(bean_master_import, future_monthly_average_price, price)

#Cleaning up the dataframe a bit
bean_master_import = bean_master_import %>%
  select(-future_date, -future_weekly_avg_price, -year) %>%
  mutate(day = day(date))

bean_master_import$future_month = factor(bean_master_import$future_month)
bean_master_import$day = factor(bean_master_import$day)
bean_master_import$class = factor(bean_master_import$class)

bean_master_import$imports = as.numeric(bean_master_import$imports)

#Setting seed for reproducibility
set.seed(42)

#First, let's cut it down to the explanatory variables we want
bean_master_import_slim = bean_master_import %>%
  select(date, class, price, whole_market_avg, whole_market_sum, 
         class_market_share, planted, harvested, yield, production,
         month, imports)

#Preprocessing
preProc2 = preProcess(bean_master_import_slim, method = c("center", "scale", "knnImpute", "zv"))
preProc2

#Doing the preprocessing
bean_ML_import_pp = predict(preProc2, bean_master_import_slim)

#glimpsing results
glimpse(bean_ML_import_pp)
bean_ML_import_pp$month = factor(bean_ML_import_pp$month)

#binding the response and dates variable back on
bean_ML_import_pp$future_monthly_avg_price = bean_master_import$future_monthly_average_price

#Training and test sets
index1 = createDataPartition(bean_ML_import_pp$future_monthly_avg_price, p = 0.80, list = FALSE)
bean_ML_import_train = bean_ML_import_pp[index1,]
bean_ML_import_test = bean_ML_import_pp[-index1,]
```


``` {r}
library(tidyverse)
library(caret)

glimpse(bean_ML_import_train)
glimpse(bean_ML_import_test)
```

So these dataframes look great - remember that the values look a little wonky because we've centered and scaled them, and that the overall goal is to predict future monthly average price given everything else. We can also look at the dimensions of the data frames (6101 rows in our training set and 1524 rows in our test set) - these make sense too, based on our previous training and test splits. 

Our basic ML pipeline is this:

**Preprocess** > **Split** > **Model Building** > **Model Testing** > **Model Tuning** 

Let's jump into some algorithms.  
It's worth talking a little bit about algorithm choice. In general, there are two big categories of predictive algorithms. First, there are those that predict classes (putting observations into categories based on other variables - think of things like tumor identification, identifying customers who might unsubscribe to a service (churn), or determining if a certain wine variety belongs in one cluster over another).  

The second are algorithms that output continuous, numeric values given a set of input variables (things like average customer rating of a book, the price of cryptocurrencies or, in our case the price of a hundred-weight of beans). I'll cover classifcation algorithms in another post, and will focus on a variety of continuous predictors here. A brief aside here - we'll also be focusing exclusively on supervised learning - unsupervised learning typically adresses a differnt set of questions (taking unlabeled data and finding patterns or classifcations within the data set) - here, we have a different goal - generate good predictive models.  

There are a bazillion different algorithms, which can be a bit daunting at first, but we'll explore a few of the basics here:  
1. Linear Regression  
2. Classification and Regression Tree (CART)  
3. Artificial Neural Net (ANN)  
4. Random Forest  

All of these algorithms have pros and cons. For example, linear regressions provide fairly interpretable mechanics (that is, we can see what the model is doing to extract what variables are the most important and how they're interacting), whereas neural netss are great at predicting really complex phenomena, but are computationally expensive (you'll see below that they can take a long time to run), and are black boxes (i.e. it's hard for humans to interpret what's happening inside them).  

## Linear Regression  
Let's start with the old standby of analysis - the linear regression. If you want a refresher on how this works, check out [this](www.wikipedia.org/wiki/Linear_regression). In its simplest form, regression models predict variability in one continuous variable based on another, generating a line that best predicts this relationship. This get's a little more complicated when the model incorporates information on many different variables, and interactions between those variables, but... that's not what this post is about. 

In all of the examples, we'll be implementing the caret package to run the models.  

The first step is to setup an object that will allow us to control parameters across all the m

``` {r} 
library(caret)

#setting seed for reproducibility:
set.seed(42)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)

```

The `trainControl` function here lets us build this object. If you check out the help page for the function, you can see there are **LOTS** of arguments - you have a lot of control over what happens in your models. Here, we're specifying that we're going to use repeated cross validation (check out [this](keatonwilson.github.io/2018/03/the-ecologist-jumps-into-the-deep-scary-waters-of-machine-learning/)), with 5 repeats and 5 folds (this is fairly robust, and we might have reduce it later on for the ANN). Because these are example models, I'm using a smaller number of repeats and folds, which can help us do quicker model assement before diving in deeper to tune models. 

Now we can run our model:  

A warning - this takes a while, mostly because we're doing a lot of model comparisons. The `train` function is splitting the training data into 10 different training and test sets 10 different times, *AND* also using the grid argument in `trainControl` to modifying different model parameters of the linear regression to tune the model simulatenously. 
``` {r, cache = TRUE}
#And just a standard linear model
lmfit1 = train(future_monthly_avg_price ~ ., data = bean_ML_import_train,
               method = "lm",
               trControl = fitControl)
```

Next, we can inspect our model, and also examine how well it did on in-sample data. 

```{r}
lmfit1
```

Not bad! You can see from the output that we have an RMSE (Root-Mean Squared Error) of 5.4, which means that on average, the model predicts bean price within $5.4 per hundred-weight, and an R-squared of 0.559 The model is only explaining around 56% of the variance in price. Remember, this is only an estimate on in-sample data using k-fold cross validation - the actual effectivness of the model might be different on test data. 

Also, the MAE parapmeter stands for Mean Absolute Error, and is another parameter we can asseess our model's fit with - also in the same units as the dependent variable (just like RMSE). A nice comparison of RMSE and MAE can be found [here](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d).

We could try and tune the model, and run it on out-of-sample test data, but let's move on to some more models. 

## Classification and Regression Tree Models

CART stands for Classification and Regression Tree. These models are a type of decision tree model, an overview of which can be found [here](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/) if you're interested in the machinery under the hood.  

```{r, cache = TRUE}
cartfit1 = train(future_monthly_avg_price ~ ., data = bean_ML_import_train,
                 method = "rpart",
                 trControl = fitControl)
cartfit1

```

So this model is worse than the old-fashioned linear regression! The best model here generates an RMSE of 6.00 and an R-squared of 0.45 - the model is predicting 45% of the variance in market prices 6 months ahead of time - not bad! 

Let's try running the model on our out-of-sample test set. 

We use two functions to do this - first the predict function, which we feed our model and the test-data set. This will use the model to build some predictions of price 6 months ahead of time which we can then compare to the actual prices in thes test set.  

We can do this comparison with the `postResample` function from caret, which compares the mean-squared error and R-squared for our predicted values and the actual values of the test set. 

```{r}
p_cartfit1 = predict(cartfit1, bean_ML_import_test)

postResample(pred = p_cartfit1, obs = bean_ML_import_test$future_monthly_avg_price)
```

So, pretty close to the measures of model performance obtained with 5-fold cross validation, though a bit worse. Overall, we're improving though. 

We could go back and tune the CART model, by changing the tuneLength argument in the train function, but let's do this on a later model - we're starting to get to the good stuff!

## Artificial Neural Net

Neural nets were designed to mimic how our brains and biological communication systems function. They're made up of a collection of units or nodes and can transmit information to each other. Deep neural nets that allow information to travel all around the network are en vogue right now, but are computationally expensive - here, we'll used a paired down version, again with the caret package. 

``` {r, cache = TRUE, results = "hide"}
nnfit2 = train(future_monthly_avg_price ~ ., data = bean_ML_import_train,
               method = "nnet",
               trControl = fitControl,
               maxit = 100,
               linout = 1, 
               verbose = FALSE)
```
Here, we specify the linout argumnet as TRUE in the train function - this lets the function know that we're interested in a linear output - otherwise a sigmoidal activation function is used, and all the predictions will be constrained between 0 and 1. 

```{r}
nnfit2
p_nnetfit2 = predict(nnfit2, bean_ML_import_test)

postResample(pred = p_nnetfit2, obs = bean_ML_import_test$future_monthly_avg_price)
```

Here, the best model in our tuning grid was one with an RMSE of $7.71/hundredweight of beans in in-sample data, which resulted in an RMSE of 7.9 on out-of-sample test data. Unfortunately, we can't extract R^2s from these data (a finciky bit of the nnet function, which I can't find an answer to!). Regardless, not much better than our linear regression. Let's move on.

## Random Forest

Random forests algorithms are a type of ensemble learning method - the idea is to construct a ton of different decision trees, and outputting the mean prediction of all of the individual trees. Here, we use the caret pacakge again, with the ranger function. 

This is going to take a while if you run it yourself...

```{r, cache = TRUE}
rffit1 =  train(future_monthly_avg_price ~ ., data = bean_ML_import_train,
                        method = "ranger",
                        trControl = fitControl)

rffit1
```

Woooooooo man! Look at those scores! The best model has an R^2 of 0.97, and an RMSE of 1.515! This is by far the best model we've tested so far. It's explaining 97% of the variance in future average monthly price!  

Let's see how it does on out-of-sample data.

```{r}
p_rffit2 = predict(rffit1, bean_ML_import_test)

postResample(pred = p_rffit2, obs = bean_ML_import_test$future_monthly_avg_price)
```

Fantastic - the model appears to have similar performance on the test data! Let's see if we can tune the model a bit more to get a bit more predictive power. 

```{r, cache = TRUE}
rffit2 =  train(future_monthly_avg_price ~ ., data = bean_ML_import_train,
                        method = "ranger",
                        trControl = fitControl, 
                        tuneLength = 5)

rffit2
```

This model took some time to run and tune, and we've improved the in-sample prediction slightly. Let's test it out on the test data. 

```{r}
p_rffit3 = predict(rffit2, bean_ML_import_test)

postResample(pred = p_rffit3, obs = bean_ML_import_test$future_monthly_avg_price)
```

This results in significant improvements - with better RMSE, Rsquared and MAE values compared to the un-tuned model. 

Finally, let's take a look at how to visualize how well our model does. 

```{r, cache = TRUE}
#binding the predictions onto the test set
bean_ML_import_test$pred = predict(rffit1, newdata = bean_ML_import_test)

#generating a plot of actual prices versus predicted future prices
ggplot(bean_ML_import_test, aes(x = pred, y = future_monthly_avg_price, color = class)) +
  geom_point() +
  theme_classic() +
  geom_abline(slope = 1, intercept = 1) +
  xlab("Predicted Future Price") +
  ylab("Actual Future Price ")

```
The black diagonal line represents the 1:1 line, dots on this line are when our model is doing a perfect job of predicting. Points above this line are scenarios where our model under-predicted price, and dots below are when the model over-predicted price. One interesting trend is that you can see that though most dots are **really** close to the line, many are just below, indicating that our model consistently slightly over-predicts price - something to keep in mind if this was going to be used for by investors. 


```{r}
#We can also plot this over time for each variety
bean_ML_import_test$date = as.Date(bean_ML_import_test$date)
bean_ML_import_test %>%
  gather(key = valuetype, value = future_price, pred, future_monthly_avg_price) %>%
ggplot(aes(x = date, y = future_price, color = class, lty = factor(valuetype))) +
         geom_path() +
        theme_classic() +
  facet_wrap( ~ class) +
  ylab("Future Price ($)") +
  xlab("Date") +
  scale_linetype_discrete(name = "",
                          labels = c("Actual Future Price", "Predicted Future Price")) +
  scale_color_discrete(name = "Variety")
```
Overall this figure matches the first figure - our model is doing a great job over time at prediction. 


## Conclusions

Overall, this post outlines one of the main goals I was working towards on this project - to develop a machine learning model that does a good job of predicting future bean prices based on current information. The best model here does a pretty amazing job at this - predicting the average monthly price six months into the future within $1.20/hundredweight across all classes. You can imagine how useful this type of predictive model might be for individuals or businsses interested in speculating on the market.  

In the next few posts, we'll look at some other interesting data from this project - and I'll introduce a basic investing/portfolio model I've built on the Machine Learning model outlined here to demonstrate how much money someone could make if they had used this model to trade beans during this period. Pretty interesting stuff!

Cheers!